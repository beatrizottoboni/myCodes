{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMbMm0dmXJqxBeb6rs0XEcV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h2>Empirical Tests for Non Stationary Data</h2>\n","<h3>By Beatriz Ottoboni</h3>\n","\n","Programa de Pós Graduação Ciência da Computação<br>\n","Disciplina Inteligência Artificial<br>\n","Professor Didier Oliveros"],"metadata":{"id":"kSUWD1GjyDee"}},{"cell_type":"markdown","source":["<h2>Summary</h2>\n","<h3><a href='#dataset'>1. Dataset Description</a></h3>\n","<h3><a href='#stat_models'>2. Statistical Models</a></h3>\n","<h4><a href='#arma'>2.1. ARMA</a><br>\n","<a href='#sarma'>2.2. Seasonal ARMA</a><br>\n","<a href='#sarima'>2.3. SARIMA</a><br>\n","<a href='#prophet'>2.4. Prophet</a></h4>\n","<h3><a href='#nn_models'>3. Neural Networks Models</a></h3>\n","<a href='#rnn'><h4>3.1. RNN</a><br>\n","<a href='#rnn_emd'>3.2. RNN with CEEMDAN</a><br>\n","<a href='#lstm'>3.3. LSTM</a><br>\n","<a href='#lstm_emd'>3.3. LSTM with CEEMDAN</a><br>\n","<a href='#n_prophet'>3.4. NeuralProphet</a><br>\n","<a href='#transformer'>3.5. Transformer</a><br>\n","<a href='#transformer_emd'>3.6. Transformer with CEEMDAN</a></h4>"],"metadata":{"id":"x0Oq0CWWzOI0"}},{"cell_type":"markdown","source":["<a id='dataset'></a><h2>1. Dataset Description"],"metadata":{"id":"CVWHQd0HxvTq"}},{"cell_type":"markdown","source":["<h4>Libraries Versions:</h4>\n","pandas==2.2.2<br>\n","numpy==1.26.4 (statistical models) / numpy==2.0.2 (neural network models)<br>\n","pmdarima==2.0.4<br>\n","statsmodels==0.14.5<br>\n","prophet==1.1.7<br>\n","sklearn==1.6.1<br>\n","math==1.1.7<br>\n","PyEMD==1.0.0<br>\n","EMD-signal==1.6.4<br>\n","scikeras==0.13.0<br>\n","neuralprophet==0.9.0<br>\n","matplotlib==3.10.0<br>\n","tsfm_public==0.3.2.dev16+g63c962f<br>\n","transformers==4.53.1<br>\n","tensorflow==2.18.0<br>\n","torch==2.6.0+cu124<br>"],"metadata":{"id":"5v5MTwyHvChQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lx-cJPH90XNt"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import statsmodels\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.stattools import adfuller\n","\n","import pmdarima as pm\n","import prophet\n","\n","import sklearn\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["path = ''"],"metadata":{"id":"8PmDht7NNkOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel(f'{path}/ipeadata_mensal.xlsx', sheet_name='consumo')\n","df = df[['Data', 'Consumo']]\n","df.columns = ['date', 'energy_consumption']\n","df = df.set_index('date')"],"metadata":{"id":"KNjSinTC02ZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 6))\n","plt.plot(df.index, df['energy_consumption'])\n","plt.title('Energy Consumption over Time')\n","plt.xlabel('date')\n","plt.ylabel('consumption')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"-NmjCc0mjeGm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Non Stationarity Test"],"metadata":{"id":"UsxSC69ohd2S"}},{"cell_type":"code","source":["print(\"ADF Test\")\n","adf_result = adfuller(df)\n","print(f'ADF Statistic: {adf_result[0]}')\n","print(f'p-value: {adf_result[1]}')\n","print(\"Non stationary (p-value > 0.1)\") if adf_result[1] > 0.1 else print(\"Stationary (p-value <= 0.1)\")"],"metadata":{"id":"0QjGEcuU393P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax1 = plt.subplots( figsize=(10, 6))\n","\n","plot_acf(df, lags=24, ax=ax1)\n","ax1.set_title('Autocorrelation Function (ACF)', fontdict={'fontsize': 25})\n","\n","plt.show()"],"metadata":{"id":"6waGR_Z75Vk_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax2 = plt.subplots(1, figsize=(10, 6))\n","\n","plot_pacf(df, lags=24, ax=ax2, method='ols')\n","ax2.set_title('Partial Autocorrelation Function (PACF)', fontdict={'fontsize': 25})"],"metadata":{"id":"ha2iDVX35coX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='stat_models'></a><h2>2. Statistical Models"],"metadata":{"id":"tR4OvDGt34FI"}},{"cell_type":"code","source":["df = df.dropna()\n","\n","df['energy_consumption_shift'] = df['energy_consumption'].shift(-1)\n","\n","X = df.values\n","size = int(len(X) * 0.9)\n","train, test = df.iloc[0:size], df.iloc[size:len(X)]\n","\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","train['energy_c_scaler'] = scaler.fit_transform(train[['energy_consumption']])\n","test['energy_c_scaler'] = scaler.transform(test[['energy_consumption']])\n","df['energy_c_scaler'] = scaler.transform(df[['energy_consumption']])\n","\n","train['energy_c_scaler_shift'] = train['energy_c_scaler'].shift(-1)\n","test['energy_c_scaler_shift'] = test['energy_c_scaler'].shift(-1)\n","df['energy_c_scaler_shift'] = df['energy_c_scaler'].shift(-1)\n","\n","test = test.dropna()\n","y_test = test['energy_consumption'].values"],"metadata":{"id":"aD31zZlW6UJc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='arma'></a><h3>2.1. ARMA"],"metadata":{"id":"u4z3vET2WT7F"}},{"cell_type":"code","source":["model_arma_selection = pm.auto_arima(train['energy_c_scaler'],\n","                      start_p=0, max_p=3,\n","                      max_d=0,\n","                      start_q=0, max_q=12,\n","                      seasonal=False,\n","                      trace=True,\n","                      stationary=True,\n","                      n_fits=10,\n","                      error_action='ignore',\n","                      scoring='mse',\n","                      suppress_warnings=True,\n","                      stepwise=True)\n"],"metadata":{"id":"_mNvLjWQWPxk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = train.dropna()\n","test_arma = test.copy()\n","predictions_arma = list()\n","\n","# walk-forward validation\n","for t in range(len(test)):\n","  model_arma = pm.arima.ARIMA(order=model_arma_selection.order, seasonal_order=model_arma_selection.seasonal_order, maxiter=50, scoring='mse')\n","  model_arma.fit(history['energy_c_scaler'])\n","  y_pred_arma = model_arma.predict().iloc[:1].values\n","  predictions_arma.append(y_pred_arma)\n","  history = pd.concat([history, test_arma.iloc[:1]])\n","  test_arma = test_arma.iloc[1:]"],"metadata":{"id":"VXX6Nm6sWdOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_arma = np.array(predictions_arma).reshape(-1, 1)\n","predictions_arma_transform = scaler.inverse_transform(predictions_arma).reshape(-1)\n","\n","# evaluate forecasts\n","rmse = sqrt(mean_squared_error(y_test, predictions_arma_transform.reshape(-1)))\n","mape = mean_absolute_percentage_error(y_test, predictions_arma_transform.reshape(-1))\n","mae = np.abs(y_test - predictions_arma_transform.reshape(-1)).mean()\n","results_arma = pd.DataFrame(data={'model': f'ARMA {model_arma.order} {model_arma.seasonal_order}', 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"no9nToRKaWLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_arma_transform).to_csv(f'{path}/preds_arma.csv', index=False)"],"metadata":{"id":"xrLdbbrsOEep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_arma"],"metadata":{"id":"h2KxM5wDL9us"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='sarma'></a><h3>2.2. Seasonal ARMA"],"metadata":{"id":"BrUit79ebFax"}},{"cell_type":"code","source":["model_s_arma_selection = pm.auto_arima(train['energy_c_scaler'],\n","                      start_p=0, max_p=3,\n","                      max_d=0,\n","                      start_q=0, max_q=6,\n","                      start_P=0, max_P=3,\n","                      max_D=0,\n","                      start_Q=0, max_Q=6,\n","                      max_order=12,\n","                      m=12, seasonal=True,\n","                      trace=True,\n","                      stationary=True,\n","                      n_fits=10,\n","                      error_action='ignore',\n","                      scoring='mse',\n","                      suppress_warnings=True,\n","                      stepwise=True)\n"],"metadata":{"id":"5TBNAIm6adiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = train.dropna()\n","test_s_arma = test.copy()\n","predictions_s_arma = list()\n","\n","# walk-forward validation\n","for t in range(len(test)):\n","  model_s_arma = pm.arima.ARIMA(order=model_s_arma_selection.order, seasonal_order=model_s_arma_selection.seasonal_order, maxiter=50, scoring='mse')\n","  model_s_arma.fit(history['energy_c_scaler'])\n","  y_pred_s_arma = model_s_arma.predict().iloc[:1].values\n","  predictions_s_arma.append(y_pred_s_arma)\n","  history = pd.concat([history, test_s_arma.iloc[:1]])\n","  test_s_arma = test_s_arma.iloc[1:]\n","\n"],"metadata":{"id":"crTKcJswdvrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_s_arma = np.array(predictions_s_arma).reshape(-1, 1)\n","predictions_s_arma_transform = scaler.inverse_transform(predictions_s_arma).reshape(-1)\n","\n","# evaluate forecasts\n","rmse = sqrt(mean_squared_error(y_test, predictions_s_arma_transform.reshape(-1)))\n","mape = mean_absolute_percentage_error(y_test, predictions_s_arma_transform.reshape(-1))\n","mae = np.abs(y_test - predictions_s_arma_transform.reshape(-1)).mean()\n","results_s_arma = pd.DataFrame(data={'model': f'Seasonal ARMA {model_s_arma.order} {model_s_arma.seasonal_order}', 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"2icQLHc1dxtt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_s_arma_transform).to_csv(f'{path}/preds_s_arma.csv', index=False)"],"metadata":{"id":"_encG6FpPnet"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_s_arma"],"metadata":{"id":"ifbBbsmOMs1m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='sarima'></a><h3>2.3. SARIMA"],"metadata":{"id":"Wp4AHDauWQJ8"}},{"cell_type":"code","source":["model_sarima_selection = pm.auto_arima(train['energy_c_scaler'],\n","                      start_p=0, max_p=3,\n","                      max_d=6,\n","                      start_q=0, max_q=12,\n","                      start_P=0, max_P=3,\n","                      max_D=6,\n","                      start_Q=0, max_Q=12,\n","                      max_order=12,\n","                      m=12, seasonal=True,\n","                      trace=True,\n","                      stationary=False,\n","                      n_fits=10,\n","                      error_action='ignore',\n","                      scoring='mse',\n","                      suppress_warnings=True,\n","                      stepwise=True)\n"],"metadata":{"id":"2C4E4RimyPDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = train.dropna()\n","test_sarima = test.copy()\n","predictions_sarima = list()\n","\n","# walk-forward validation\n","for t in range(len(test)):\n","  model_sarima = pm.arima.ARIMA(order=model_sarima_selection.order, seasonal_order=model_sarima_selection.seasonal_order, maxiter=50, scoring='mse')\n","  model_sarima.fit(history['energy_c_scaler'])\n","  y_pred_sarima = model_sarima.predict().iloc[:1].values\n","  predictions_sarima.append(y_pred_sarima)\n","  history = pd.concat([history, test_sarima.iloc[:1]])\n","  test_sarima = test_sarima.iloc[1:]"],"metadata":{"id":"9nzomtM_mfSt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_sarima = np.array(predictions_sarima).reshape(-1, 1)\n","predictions_sarima_transform = scaler.inverse_transform(predictions_sarima).reshape(-1)\n","\n","# evaluate forecasts\n","rmse = sqrt(mean_squared_error(y_test, predictions_sarima_transform.reshape(-1)))\n","mape = mean_absolute_percentage_error(y_test, predictions_sarima_transform.reshape(-1))\n","mae = np.abs(y_test - predictions_sarima_transform.reshape(-1)).mean()\n","results_sarima = pd.DataFrame(data={'model': f'SARIMA {model_sarima.order} {model_sarima.seasonal_order}', 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"ieev_WBEPURz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_sarima_transform).to_csv(f'{path}/preds_sarima.csv', index=False)"],"metadata":{"id":"jNmwiY6DPjOz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_sarima"],"metadata":{"id":"IJAfSHkSoePr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='prophet'></a><h3>2.4. Prophet"],"metadata":{"id":"8OLBPXv843uE"}},{"cell_type":"code","source":["train_prophet = train.reset_index()\n","train_prophet = train_prophet[['date', 'energy_c_scaler']]\n","train_prophet.columns = ['ds', 'y']\n","\n","test_prophet = test.reset_index()\n","test_prophet = test_prophet[['date', 'energy_c_scaler']]\n","test_prophet.columns = ['ds', 'y']"],"metadata":{"id":"xdNgM7QAewzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = train_prophet.dropna()\n","test_prophet_val = test_prophet.copy()\n","predictions_prophet = pd.DataFrame()\n","\n","# walk-forward validation\n","for t in range(len(test_prophet_val)):\n","  model_prophet = prophet.Prophet()\n","  model_prophet.fit(history)\n","  y_pred_prophet = model_prophet.predict(test_prophet_val.iloc[:1][['ds']])[['ds', 'yhat']]\n","  predictions_prophet = pd.concat([predictions_prophet, y_pred_prophet])\n","  history = pd.concat([history, test_prophet_val.iloc[:1]])\n","  test_prophet_val = test_prophet_val.iloc[1:]"],"metadata":{"id":"7fAeoUSPHjB2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_prophet_transform = np.array(predictions_prophet['yhat']).reshape(-1, 1)\n","predictions_prophet_transform = scaler.inverse_transform(predictions_prophet_transform).reshape(-1)\n","\n","# evaluate forecasts\n","rmse = sqrt(mean_squared_error(y_test, predictions_prophet_transform))\n","mape = mean_absolute_percentage_error(y_test, predictions_prophet_transform)\n","mae = np.abs(y_test - predictions_prophet_transform).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","results_prophet = pd.DataFrame(data={'model': f\"Prophet\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"27DYEQmrhXM8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_prophet_transform).to_csv(f'{path}/preds_prophet.csv', index=False)"],"metadata":{"id":"S9FfgDjLPXwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_prophet"],"metadata":{"id":"dEfsR5HslxNH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='nn_models'></a><h2>3. Neural Networks Models"],"metadata":{"id":"RBxDulrq45q3"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from PyEMD.CEEMDAN import CEEMDAN\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_percentage_error\n","from math import sqrt\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, SimpleRNN\n","from neuralprophet import NeuralProphet\n","\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","\n","from transformers import (\n","    EarlyStoppingCallback,\n","    PatchTSTConfig,\n","    PatchTSTForPrediction,\n","    set_seed,\n","    Trainer,\n","    TrainingArguments\n",")\n","\n","from tsfm_public.toolkit.dataset import ForecastDFDataset\n","from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n","from tsfm_public.toolkit.util import select_by_index\n","\n","warnings.filterwarnings(\"ignore\", module=\"torch\")\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"_-QPclPoiH1f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"metadata":{"id":"5YErX4wrWbKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_excel(f'{path}/ipeadata_mensal.xlsx', sheet_name='consumo')\n","df = df[['Data', 'Consumo']]\n","df.columns = ['date', 'energy_consumption']\n","df['energy_consumption_shift'] = df['energy_consumption'].shift(-1)"],"metadata":{"id":"HbNrO5kfMvxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.values\n","size = int(len(X) * 0.9)\n","train, test = df.iloc[0:size], df.iloc[size:len(X)]"],"metadata":{"id":"YShO1gCYMR5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler(feature_range=(0, 1))\n","train['energy_c_scaler'] = scaler.fit_transform(train[['energy_consumption']])\n","test['energy_c_scaler'] = scaler.transform(test[['energy_consumption']])\n","df['energy_c_scaler'] = scaler.transform(df[['energy_consumption']])\n","\n","\n","train['energy_c_scaler_shift'] = train['energy_c_scaler'].shift(-1)\n","test['energy_c_scaler_shift'] = test['energy_c_scaler'].shift(-1)\n","df['energy_c_scaler_shift'] = df['energy_c_scaler'].shift(-1)\n","\n","test = test.dropna()\n","y_test = test['energy_consumption_shift'].values"],"metadata":{"id":"CE7e2_vKsygT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_imf = 4\n","ceemdan = CEEMDAN()\n","\n","IMFs = pd.DataFrame(ceemdan(np.array(train['energy_c_scaler']), max_imf=num_imf)).T\n","train_imf = pd.concat([train, IMFs], axis=1)\n","train_imf.columns = ['date', 'energy_consumption', 'energy_consumption_shift', 'energy_c_scaler', 'energy_c_scaler_shift', 'imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']\n","fig, axes = plt.subplots(num_imf+1, 1, figsize=(12, 1 * (num_imf+1)), sharex=True)\n","for i in range(num_imf+1):\n","  axes[i].plot(IMFs[i], label=f'IMF {i}')\n","  axes[i].legend(loc='upper right')\n","  axes[i].grid(True)\n","  axes[-1].set_xlabel('Amostras')\n","  plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Y-nd_f42JUWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_imf = 4\n","ceemdan = CEEMDAN()\n","IMFs_total = pd.DataFrame(ceemdan(np.array(df['energy_c_scaler']), max_imf=num_imf)).T\n","imf = pd.concat([df, IMFs_total], axis=1)\n","imf.columns = ['date', 'energy_consumption', 'energy_consumption_shift', 'energy_c_scaler', 'energy_c_scaler_shift', 'imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']"],"metadata":{"id":"oQOfW6gj8kFl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_imf = train_imf.dropna()\n","imf = imf.dropna()"],"metadata":{"id":"DHT1CrGa52KB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='rnn'></a><h3>3.1. RNN"],"metadata":{"id":"C7b0nhyu6MtI"}},{"cell_type":"code","source":["history = [x for x in train]\n","predictions_rnn = list()\n","\n","train_rnn = train_imf[['energy_c_scaler','energy_c_scaler_shift']]\n","test_rnn = imf.iloc[size:-1][['energy_c_scaler', 'energy_c_scaler_shift']]\n","print(train_rnn.shape, test_rnn.shape)\n","\n","# walk-forward validation\n","for t in range(len(test)-1):\n","\n","  X_train_rnn = train_rnn[['energy_c_scaler']]\n","  y_train_rnn = train_rnn['energy_c_scaler_shift']\n","\n","  X_test_rnn = test_rnn[['energy_c_scaler']]\n","  y_test_rnn = test_rnn['energy_c_scaler_shift']\n","\n","  size_train = int(len(X_train_rnn.values) * 0.9)\n","  X_val_rnn = X_train_rnn[size_train:]\n","  y_val_rnn = X_train_rnn[size_train:]\n","  X_train_rnn_ = X_train_rnn.iloc[0:size_train]\n","  y_train_rnn_ = y_train_rnn.iloc[0:size_train]\n","\n","  X_test_reshape = np.reshape(X_test_rnn, (X_test_rnn.shape[0], 1, X_test_rnn.shape[1]))\n","  y_test_reshape = np.array(y_test_rnn)\n","\n","  X_train_reshape = np.reshape(X_train_rnn_, (X_train_rnn_.shape[0], 1, X_train_rnn_.shape[1]))\n","  y_train_reshape = np.array(y_train_rnn_)\n","\n","  X_val_reshape = np.reshape(X_val_rnn, (X_val_rnn.shape[0], 1, X_val_rnn.shape[1]))\n","  y_val_reshape = np.array(y_val_rnn)\n","\n","  rnn_model = Sequential()\n","  rnn_model.add(SimpleRNN(units=4, input_shape=(X_train_reshape.shape[1], X_train_reshape.shape[2])))\n","  rnn_model.add(Dense(1, activation='sigmoid'))\n","  rnn_model.compile(loss='mse', optimizer='Adam')\n","\n","  # Train the final model on the entire training dataset\n","  rnn_model.fit(X_train_reshape, y_train_reshape, epochs=100, batch_size=1, verbose=0)\n","\n","  # Evaluate the model on the validation set\n","  loss = rnn_model.evaluate(X_val_reshape, y_val_reshape, verbose=0)\n","  print(f'Test loss (MSE): {loss}')\n","\n","  # Make predictions on the test set\n","  y_pred = rnn_model.predict(X_test_reshape)\n","\n","  y_pred_transform = scaler.inverse_transform(y_pred)\n","\n","  predictions_rnn.append(y_pred_transform[0])\n","\n","  train_rnn = pd.concat([train_rnn, test_rnn.iloc[:1]])\n","  test_rnn = test_rnn.iloc[1:]\n","\n","  print(train_rnn.shape, test_rnn.shape)"],"metadata":{"id":"mctwzynO517T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_rnn).to_csv(f'{path}/preds_rnn.csv', index=False)"],"metadata":{"id":"Oe8xom5E9RLh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_rnn = pd.read_csv(f'{path}/preds_rnn.csv')"],"metadata":{"id":"6Afnd3BqsR7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_rnn))\n","mape = mean_absolute_percentage_error(y_test, predictions_rnn)\n","mae = np.abs(y_test - predictions_rnn.values).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","rnn_value = pd.DataFrame(data={'model': f\"LSTM\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"2WkxP58E9r_Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='rnn_emd'></a><h3>3.2. RNN with CEEMDAN"],"metadata":{"id":"SyfCqYfzc7Xf"}},{"cell_type":"code","source":["history = [x for x in train]\n","predictions_rnn_c_ceemdan = list()\n","\n","train_rnn_c = train_imf[['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4','energy_c_scaler','energy_c_scaler_shift']]\n","test_rnn_c = imf.iloc[size:-1][['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4', 'energy_c_scaler_shift']]\n","print(train_rnn_c.shape, test_rnn_c.shape)\n","\n","# walk-forward validation\n","for t in range(len(test)-1):\n","\n","  X_train_rnn_c = train_rnn_c[['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']]\n","  y_train_rnn_c = train_rnn_c['energy_c_scaler_shift']\n","\n","  X_test_rnn_c = test_rnn_c[['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']]\n","  y_test_rnn_c = test_rnn_c['energy_c_scaler_shift']\n","\n","  size_train = int(len(X_train_rnn_c.values) * 0.9)\n","  X_val_rnn_c = X_train_rnn_c[size_train:]\n","  y_val_rnn_c = X_train_rnn_c[size_train:]\n","  X_train_rnn_c_ = X_train_rnn_c.iloc[0:size_train]\n","  y_train_rnn_c_ = y_train_rnn_c.iloc[0:size_train]\n","\n","  X_test_reshape = np.reshape(X_test_rnn_c, (X_test_rnn_c.shape[0], 1, X_test_rnn_c.shape[1]))\n","  y_test_reshape = np.array(y_test_rnn_c)\n","\n","  X_train_reshape = np.reshape(X_train_rnn_c_, (X_train_rnn_c_.shape[0], 1, X_train_rnn_c_.shape[1]))\n","  y_train_reshape = np.array(y_train_rnn_c_)\n","\n","  X_val_reshape = np.reshape(X_val_rnn_c, (X_val_rnn_c.shape[0], 1, X_val_rnn_c.shape[1]))\n","  y_val_reshape = np.array(y_val_rnn_c)\n","\n","\n","  rnn_c_model = Sequential()\n","  rnn_c_model.add(SimpleRNN(units=16, input_shape=(X_train_reshape.shape[1], X_train_reshape.shape[2]), return_sequences=True))\n","  rnn_c_model.add(SimpleRNN(units=16))\n","  rnn_c_model.add(Dense(1, activation='sigmoid'))\n","  rnn_c_model.compile(loss='mse', optimizer='Adam')\n","\n","  # Train the final model on the entire training dataset\n","  rnn_c_model.fit(X_train_reshape, y_train_reshape, epochs=50, batch_size=1, verbose=0)\n","\n","  # Evaluate the model on the validation set\n","  loss = rnn_c_model.evaluate(X_val_reshape, y_val_reshape, verbose=0)\n","  print(f'Test loss (MSE): {loss}')\n","\n","  # Make predictions on the test set\n","  y_pred = rnn_c_model.predict(X_test_reshape)\n","\n","  y_pred_transform = scaler.inverse_transform(y_pred)\n","\n","  predictions_rnn_c_ceemdan.append(y_pred_transform[0])\n","\n","  train_rnn_c = pd.concat([train_rnn_c, test_rnn_c.iloc[:1]])\n","  test_rnn_c = test_rnn_c.iloc[1:]\n","\n","  print(train_rnn_c.shape, test_rnn_c.shape)\n"],"metadata":{"id":"Kaq46TMUc61o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_rnn_c_ceemdan).to_csv(f'{path}/preds_rnn_c.csv', index=False)"],"metadata":{"id":"kLKLQJNcc6ZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_rnn_c_ceemdan = pd.read_csv(f'{path}/preds_rnn_c.csv')"],"metadata":{"id":"6Tc0FYp5O75I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_rnn_c_ceemdan))\n","mape = mean_absolute_percentage_error(y_test, predictions_rnn_c_ceemdan)\n","mae = np.abs(y_test - predictions_rnn_c_ceemdan.values).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","rnn_ceemdan_value = pd.DataFrame(data={'model': f\"LSTM\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"k_wrybBTgqw8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='lstm'></a><h3>3.3. LSTM"],"metadata":{"id":"knRIhjzP1Sn-"}},{"cell_type":"code","source":["history = [x for x in train]\n","predictions_lstm = list()\n","\n","train_lstm = train_imf[['energy_c_scaler','energy_c_scaler_shift']]\n","test_lstm = imf.iloc[size:-1][['energy_c_scaler', 'energy_c_scaler_shift']]\n","print(train_lstm.shape, test_lstm.shape)\n","\n","# walk-forward validation\n","for t in range(len(test)-1):\n","\n","  X_train_lstm = train_lstm[['energy_c_scaler']]\n","  y_train_lstm = train_lstm['energy_c_scaler_shift']\n","\n","  X_test_lstm = test_lstm[['energy_c_scaler']]\n","  y_test_lstm = test_lstm['energy_c_scaler_shift']\n","\n","  size_train = int(len(X_train_lstm.values) * 0.9)\n","  X_val_lstm = X_train_lstm[size_train:]\n","  y_val_lstm = X_train_lstm[size_train:]\n","  X_train_lstm_ = X_train_lstm.iloc[0:size_train]\n","  y_train_lstm_ = y_train_lstm.iloc[0:size_train]\n","\n","  X_test_reshape = np.reshape(X_test_lstm, (X_test_lstm.shape[0], 1, X_test_lstm.shape[1]))\n","  y_test_reshape = np.array(y_test_lstm)\n","\n","  X_train_reshape = np.reshape(X_train_lstm_, (X_train_lstm_.shape[0], 1, X_train_lstm_.shape[1]))\n","  y_train_reshape = np.array(y_train_lstm_)\n","\n","  X_val_reshape = np.reshape(X_val_lstm, (X_val_lstm.shape[0], 1, X_val_lstm.shape[1]))\n","  y_val_reshape = np.array(y_val_lstm)\n","\n","  lstm_model = Sequential()\n","  lstm_model.add(LSTM(units=4, input_shape=(X_train_reshape.shape[1], X_train_reshape.shape[2])))\n","  lstm_model.add(Dense(1, activation='sigmoid'))\n","  lstm_model.compile(loss='mse', optimizer='Adam')\n","\n","  # Train the final model on the entire training dataset\n","  lstm_model.fit(X_train_reshape, y_train_reshape, epochs=100, batch_size=1, verbose=0)\n","\n","  # Evaluate the model on the validation set\n","  loss = lstm_model.evaluate(X_val_reshape, y_val_reshape, verbose=0)\n","  print(f'Test loss (MSE): {loss}')\n","\n","  # Make predictions on the test set\n","  y_pred = lstm_model.predict(X_test_reshape)\n","\n","  y_pred_transform = scaler.inverse_transform(y_pred)\n","\n","  predictions_lstm.append(y_pred_transform[0])\n","\n","  train_lstm = pd.concat([train_lstm, test_lstm.iloc[:1]])\n","  test_lstm = test_lstm.iloc[1:]\n","\n","  print(train_lstm.shape, test_lstm.shape)\n"],"metadata":{"id":"VLHesxIvk-MJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_lstm).to_csv(f'{path}/preds_lstm.csv', index=False)"],"metadata":{"id":"kNIvP84JP8Xe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_lstm = pd.read_csv(f'{path}/preds_lstm.csv')"],"metadata":{"id":"qfLNUn1FsxEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_lstm))\n","mape = mean_absolute_percentage_error(y_test, predictions_lstm - 1)\n","mae = np.abs(y_test - predictions_lstm.values).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","lstm_value = pd.DataFrame(data={'model': f\"LSTM\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"iVkDMc2nJVvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='lstm_emd'></a><h3>3.3. LSTM with CEEMDAN"],"metadata":{"id":"g0H0MyXC1iul"}},{"cell_type":"code","source":["history = [x for x in train]\n","predictions_lstm_ceemdan = list()\n","\n","train_lstm_ceemdan = train_imf[['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4','energy_c_scaler','energy_c_scaler_shift']]\n","test_lstm_ceemdan = imf.iloc[size:-1][['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4', 'energy_c_scaler_shift']]\n","print(train_lstm_ceemdan.shape, test_lstm_ceemdan.shape)\n","\n","# walk-forward validation\n","\n","for t in range(len(test)-1):\n","\n","  X_train_lstm_ceemdan = train_lstm_ceemdan[['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']]\n","  y_train_lstm_ceemdan = train_lstm_ceemdan['energy_c_scaler_shift']\n","\n","  X_test_lstm_ceemdan = test_lstm_ceemdan[['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']]\n","  y_test_lstm_ceemdan = test_lstm_ceemdan['energy_c_scaler_shift']\n","\n","  size_train = int(len(X_train_lstm_ceemdan.values) * 0.9)\n","  X_val_lstm_ceemdan = X_train_lstm_ceemdan[size_train:]\n","  y_val_lstm_ceemdan = X_train_lstm_ceemdan[size_train:]\n","  X_train_lstm_ceemdan_ = X_train_lstm_ceemdan.iloc[0:size_train]\n","  y_train_lstm_ceemdan_ = y_train_lstm_ceemdan.iloc[0:size_train]\n","\n","  X_test_reshape = np.reshape(X_test_lstm_ceemdan, (X_test_lstm_ceemdan.shape[0], 1, X_test_lstm_ceemdan.shape[1]))\n","  y_test_reshape = np.array(y_test_lstm_ceemdan)\n","\n","  X_train_reshape = np.reshape(X_train_lstm_ceemdan_, (X_train_lstm_ceemdan_.shape[0], 1, X_train_lstm_ceemdan_.shape[1]))\n","  y_train_reshape = np.array(y_train_lstm_ceemdan_)\n","\n","  X_val_reshape = np.reshape(X_val_lstm_ceemdan, (X_val_lstm_ceemdan.shape[0], 1, X_val_lstm_ceemdan.shape[1]))\n","  y_val_reshape = np.array(y_val_lstm_ceemdan)\n","\n","  lstm_ceemdan_model = Sequential()\n","  lstm_ceemdan_model.add(LSTM(units=16, input_shape=(X_train_reshape.shape[1], X_train_reshape.shape[2]), return_sequences=True))\n","  lstm_ceemdan_model.add(LSTM(units=16))\n","  lstm_ceemdan_model.add(Dense(1, activation='sigmoid'))\n","  lstm_ceemdan_model.compile(loss='mse', optimizer='Adam')\n","\n","  # Train the final model on the entire training dataset\n","  lstm_ceemdan_model.fit(X_train_reshape, y_train_reshape, epochs=50, batch_size=1, verbose=0)\n","\n","  # Evaluate the model on the validation set\n","  loss = lstm_ceemdan_model.evaluate(X_val_reshape, y_val_reshape, verbose=0)\n","  print(f'Test loss (MSE): {loss}')\n","\n","  # Make predictions on the test set\n","  y_pred = lstm_ceemdan_model.predict(X_test_reshape)\n","\n","  y_pred_transform = scaler.inverse_transform(y_pred)\n","\n","  predictions_lstm_ceemdan.append(y_pred_transform[0])\n","\n","  train_lstm_ceemdan = pd.concat([train_lstm_ceemdan, test_lstm_ceemdan.iloc[:1]])\n","  test_lstm_ceemdan = test_lstm_ceemdan.iloc[1:]\n","\n","  print(train_lstm_ceemdan.shape, test_lstm_ceemdan.shape)"],"metadata":{"id":"yWlbut9VPSXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_lstm_ceemdan).to_csv(f'{path}/preds_lstm_ceemdan.csv', index=False)"],"metadata":{"id":"ic-JFAWkyks6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_lstm_ceemdan = pd.read_csv(f'{path}/preds_lstm_ceemdan.csv')"],"metadata":{"id":"b8bu-IW0Qaf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_lstm_ceemdan))\n","mape = mean_absolute_percentage_error(y_test, predictions_lstm_ceemdan - 1)\n","mae = np.abs(y_test - predictions_lstm_ceemdan.values).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","lstm_ceemdan_value = pd.DataFrame(data={'model': f\"LSTM\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"VSSRe2h5yrJq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='n_prophet'></a><h3>3.4. NeuralProphet"],"metadata":{"id":"wDurH5e57j2m"}},{"cell_type":"code","source":["df_neuralprophet = df[['date', 'energy_c_scaler', 'energy_c_scaler_shift', 'energy_consumption', 'energy_consumption_shift']]\n","df_neuralprophet.columns = ['ds', 'y', 'y_shift', 'energy_consumption', 'energy_consumption_shift']\n","\n","X = df_neuralprophet.values\n","size = int(len(X) * 0.9)\n","train_neuralprophet, test_neuralprophet = df_neuralprophet.iloc[0:size], df_neuralprophet.iloc[size:]\n","\n","train_neuralprophet = train_neuralprophet[['ds', 'y']]\n","test_neuralprophet = test_neuralprophet.dropna()[['ds', 'y']]"],"metadata":{"id":"qZugsrh4ROft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = [x for x in train]\n","predictions_neuralprophet = pd.DataFrame()\n","\n","train_neuralprophe_pred = train_neuralprophet[:size]\n","test_neuralprophet_pred = test_neuralprophet.copy()\n","\n","print(train_neuralprophe_pred.shape, test_neuralprophet_pred.shape)\n","\n","# walk-forward validation\n","\n","for t in range(len(test_neuralprophet)):\n","\n","  size_val = int(len(train_neuralprophe_pred.values) * 0.9)\n","  train_neuralprophe_pred_ = train_neuralprophe_pred[:size_val]\n","  val_neuralprophe_pred = train_neuralprophe_pred[size_val:]\n","\n","  model_neuralprophet = NeuralProphet()\n","  model_neuralprophet.fit(train_neuralprophe_pred_, freq=\"M\", metrics='mse',\n","                          validation_df=val_neuralprophe_pred)\n","\n","  y_pred = model_neuralprophet.predict(test_neuralprophet_pred[:1])\n","  predictions_neuralprophet = pd.concat([predictions_neuralprophet, y_pred])\n","\n","  train_neuralprophe_pred = pd.concat([train_neuralprophe_pred, test_neuralprophet_pred.iloc[:1]])\n","  test_neuralprophet_pred = test_neuralprophet_pred.iloc[1:]\n","\n","  print(train_neuralprophe_pred.shape, test_neuralprophet_pred.shape)"],"metadata":{"id":"p1VMHJlNZCcY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_neuralprophet).to_csv(f'{path}/preds_neuralprophet.csv', index=False)"],"metadata":{"id":"InGVhuGpjmY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_neuralprophet_transform = scaler.inverse_transform(np.array(predictions_neuralprophet['yhat1']).reshape(-1, 1))\n","\n","# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_neuralprophet_transform))\n","mape = mean_absolute_percentage_error(y_test, predictions_neuralprophet_transform - 1)\n","mae = np.abs(y_test - predictions_neuralprophet_transform).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","lstm_ceemdan_value = pd.DataFrame(data={'model': f\"LSTM\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"Zz4Ud-X31uQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='transformer'></a><h3>3.5. Transformer"],"metadata":{"id":"BrijXJ7p5YdW"}},{"cell_type":"code","source":["def get_datasets(num_train, num_test, num_valid, df_transformer):\n","\n","  border1s = [0, num_train - context_length, len(df_transformer) - num_test - context_length,]\n","  border2s = [num_train, num_train + num_valid, len(df_transformer)]\n","\n","  train_start_index = border1s[0]\n","  train_end_index = border2s[0]\n","  valid_start_index = border1s[1]\n","  valid_end_index = border2s[1]\n","  test_start_index = border1s[2]\n","  test_end_index = border2s[2]\n","\n","  train_data = select_by_index(\n","      df_transformer,\n","      id_columns=id_columns,\n","      start_index=train_start_index,\n","      end_index=train_end_index)\n","  valid_data = select_by_index(\n","      df_transformer,\n","      id_columns=id_columns,\n","      start_index=valid_start_index,\n","      end_index=valid_end_index)\n","  test_data = select_by_index(\n","      df_transformer,\n","      id_columns=id_columns,\n","      start_index=test_start_index,\n","      end_index=test_end_index)\n","\n","  time_series_preprocessor = TimeSeriesPreprocessor(\n","      timestamp_column=timestamp_column,\n","      id_columns=id_columns,\n","      input_columns=forecast_columns,\n","      output_columns=forecast_columns,\n","      scaling=False)\n","  time_series_preprocessor = time_series_preprocessor.train(train_data)\n","\n","  train_dataset = ForecastDFDataset(\n","      time_series_preprocessor.preprocess(train_data),\n","      id_columns=id_columns,\n","      timestamp_column=\"date\",\n","      target_columns=forecast_columns,\n","      context_length=context_length,\n","      prediction_length=forecast_horizon)\n","  valid_dataset = ForecastDFDataset(\n","      time_series_preprocessor.preprocess(valid_data),\n","      id_columns=id_columns,\n","      timestamp_column=\"date\",\n","      target_columns=forecast_columns,\n","      context_length=context_length,\n","      prediction_length=forecast_horizon)\n","  test_dataset = ForecastDFDataset(\n","      time_series_preprocessor.preprocess(test_data),\n","      id_columns=id_columns,\n","      timestamp_column=\"date\",\n","      target_columns=forecast_columns,\n","      context_length=context_length,\n","      prediction_length=forecast_horizon,)\n","\n","  return train_dataset, valid_dataset, test_dataset"],"metadata":{"id":"jNH6s5fDYH_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["timestamp_column = \"date\"\n","id_columns = []\n","\n","df_transformer = df[['date', 'energy_c_scaler']]\n","\n","num_input = len(df_transformer.columns) - 1\n","context_length = 2\n","forecast_columns = list(df_transformer.columns[1:])\n","forecast_horizon = 1\n","num_workers = 4\n","batch_size = 64"],"metadata":{"id":"ZJTZrproWTSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_train = int(len(df_transformer) * 0.81)\n","num_test = int(len(df_transformer) * 0.1)\n","num_valid = len(df_transformer) - num_train - num_test\n","\n","predictions_transformer = pd.DataFrame()\n","\n","for i in range(int(len(df_transformer) * 0.1)):\n","  train_dataset, valid_dataset, test_dataset = get_datasets(num_train, num_test, num_valid, df_transformer)\n","\n","  finetune_forecast_model = PatchTSTForPrediction.from_pretrained(\n","    pretrained_model_name_or_path='ibm-research/patchtst-etth1-pretrain',\n","    config = PatchTSTConfig(\n","      context_length=2,\n","      prediction_length=forecast_horizon,\n","      loss=\"mse\"))\n","\n","  finetune_forecast_args = TrainingArguments(\n","      output_dir=f\"{path}/output/\",\n","      overwrite_output_dir=True,\n","      learning_rate=0.0001,\n","      num_train_epochs=20,\n","      do_eval=True,\n","      eval_strategy=\"steps\",\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      dataloader_num_workers=num_workers,\n","      report_to=\"tensorboard\",\n","      save_strategy=\"steps\",\n","      save_steps=100,\n","      logging_strategy=\"steps\",\n","      logging_steps=100,\n","      save_total_limit=2,\n","      logging_dir=f\"{path}/logs/\",  # Make sure to specify a logging directory\n","      load_best_model_at_end=True,  # Load the best model when training ends\n","      metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n","      greater_is_better=False,  # For loss\n","      label_names=[\"future_values\"])\n","\n","  early_stopping_callback = EarlyStoppingCallback(\n","      early_stopping_patience=5,  # Number of epochs with no improvement after which to stop\n","      early_stopping_threshold=0.01)  # Minimum improvement required to consider as improvement\n","\n","  finetune_forecast_trainer = Trainer(\n","      model=finetune_forecast_model,\n","      args=finetune_forecast_args,\n","      train_dataset=train_dataset,\n","      eval_dataset=valid_dataset,\n","      callbacks=[early_stopping_callback])\n","\n","  for param in finetune_forecast_trainer.model.model.parameters():\n","      param.requires_grad = False\n","\n","  finetune_forecast_trainer.train()\n","  result = finetune_forecast_trainer.evaluate(valid_dataset)\n","\n","  test_result = finetune_forecast_trainer.evaluate(test_dataset)\n","  print(test_result)\n","\n","  output = finetune_forecast_trainer.predict(test_dataset)\n","\n","  try:\n","    y_pred_transform = output.predictions[1]\n","  except:\n","    y_pred_transform = output.predictions[0]\n","  display(y_pred_transform.shape)\n","  # print(y_pred_transform)\n","\n","  predictions_transformer = pd.concat([predictions_transformer, pd.DataFrame(y_pred_transform.reshape(-1, 1)).T])\n","  print(predictions_transformer.shape)\n","\n","  num_train = num_train + 1\n","  num_test = num_test - 1"],"metadata":{"id":"NXB-yjIp8ddj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_transformer_transform = np.array(predictions_transformer.iloc[:-1, 0]).reshape(-1, 1)\n","predictions_transformer_transform = scaler.inverse_transform(predictions_transformer_transform)\n","display(predictions_transformer_transform.shape)\n","\n","pd.DataFrame(predictions_transformer).to_csv(f'{path}/preds_transformer.csv', index=False)"],"metadata":{"id":"Knrfn39F2hdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_transformer_transform))\n","mape = mean_absolute_percentage_error(y_test, predictions_transformer_transform)\n","mae = np.abs(y_test - predictions_transformer_transform).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","transformer_value = pd.DataFrame(data={'model': f\"PatchTST Transformer\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"z4jAKxijGXBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer_value"],"metadata":{"id":"tC2JjqexGXm1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a id='=transformer_emd'></a><h3>3.6. Transformer with CEEMDAN</h3>"],"metadata":{"id":"QQ9kv-6A3aKC"}},{"cell_type":"code","source":["timestamp_column = \"date\"\n","id_columns = []\n","\n","df_transformer_c = imf[['date', 'imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']]\n","\n","num_input = len(df_transformer_c.columns) - 1\n","context_length = 2\n","forecast_columns = list(df_transformer_c.columns[1:])\n","forecast_horizon = 1\n","num_workers = 4\n","batch_size = 64"],"metadata":{"id":"Nh55Y14LwrhR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_train = int(len(df_transformer_c) * 0.81)\n","num_test = int(len(df_transformer_c) * 0.1)\n","num_valid = len(df_transformer_c) - num_train - num_test\n","\n","predictions_transformer_c = pd.DataFrame()\n","\n","for i in range(int(len(df_transformer_c) * 0.1)):\n","  train_dataset, valid_dataset, test_dataset = get_datasets(num_train, num_test, num_valid, df_transformer_c)\n","\n","  finetune_forecast_model = PatchTSTForPrediction.from_pretrained(\n","    pretrained_model_name_or_path='ibm-research/patchtst-etth1-pretrain',\n","    config = PatchTSTConfig(\n","      num_input_channels=num_input,\n","      context_length=context_length,\n","      prediction_length=forecast_horizon,\n","      loss=\"mse\"))\n","\n","  finetune_forecast_args = TrainingArguments(\n","      output_dir=f\"{path}/output/\",\n","      overwrite_output_dir=True,\n","      learning_rate=0.0001,\n","      num_train_epochs=20,\n","      do_eval=True,\n","      eval_strategy=\"steps\",\n","      per_device_train_batch_size=batch_size,\n","      per_device_eval_batch_size=batch_size,\n","      dataloader_num_workers=num_workers,\n","      report_to=\"tensorboard\",\n","      save_strategy=\"steps\",\n","      save_steps=100,\n","      logging_strategy=\"steps\",\n","      logging_steps=100,\n","      save_total_limit=2,\n","      logging_dir=f\"{path}/logs/\",  # Make sure to specify a logging directory\n","      load_best_model_at_end=True,  # Load the best model when training ends\n","      metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n","      greater_is_better=False,  # For loss\n","      label_names=[\"future_values\"])\n","\n","  early_stopping_callback = EarlyStoppingCallback(\n","      early_stopping_patience=5,  # Number of epochs with no improvement after which to stop\n","      early_stopping_threshold=0.01)  # Minimum improvement required to consider as improvement\n","\n","  finetune_forecast_trainer = Trainer(\n","      model=finetune_forecast_model,\n","      args=finetune_forecast_args,\n","      train_dataset=train_dataset,\n","      eval_dataset=valid_dataset,\n","      callbacks=[early_stopping_callback])\n","\n","  for param in finetune_forecast_trainer.model.model.parameters():\n","      param.requires_grad = False\n","\n","  finetune_forecast_trainer.train()\n","  result_c = finetune_forecast_trainer.evaluate(valid_dataset)\n","\n","  test_result_c = finetune_forecast_trainer.evaluate(test_dataset)\n","  print(test_result_c)\n","\n","  output_c = finetune_forecast_trainer.predict(test_dataset)\n","\n","  try:\n","    y_pred_transform_c = pd.DataFrame(output_c.predictions[1][0])\n","  except:\n","    y_pred_transform_c = pd.DataFrame(output_c.predictions[0][0])\n","  display(y_pred_transform_c.shape)\n","\n","  predictions_transformer_c = pd.concat([predictions_transformer_c, y_pred_transform_c])\n","  print(predictions_transformer_c.shape)\n","\n","  num_train = num_train + 1\n","  num_test = num_test - 1"],"metadata":{"id":"onpp9-RMwxs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_transformer_c.columns = ['imf_0', 'imf_1', 'imf_2', 'imf_3', 'imf_4']\n","predictions_transformer_c['pred'] = predictions_transformer_c.sum(axis=1)"],"metadata":{"id":"gFfuObuc-YN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_transformer_c_transform = scaler.inverse_transform(np.array(predictions_transformer_c['pred']).reshape(-1, 1))\n","display(predictions_transformer_c_transform.shape)"],"metadata":{"id":"FdBFRunt_GDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(predictions_transformer_c_transform).to_csv(f'{path}/preds_transformer_c.csv', index=False)"],"metadata":{"id":"oKRuFXJOyVY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate evaluation metrics (RMSE, MAPE, MAE)\n","rmse = sqrt(mean_squared_error(y_test, predictions_transformer_c_transform))\n","mape = mean_absolute_percentage_error(y_test, predictions_transformer_c_transform)\n","mae = np.abs(y_test - predictions_transformer_c_transform).mean()\n","\n","print(f'Test RMSE: {rmse}')\n","print(f'Test MAPE: {mape}')\n","print(f'Test MAE: {mae}')\n","\n","# Store the results\n","transformer_c_value = pd.DataFrame(data={'model': f\"PatchTST Transformer\", 'rmse':[rmse], 'mape':[mape], 'mae':[mae]})"],"metadata":{"id":"nyqqaNgMDImP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_arma = pd.read_csv(f'{path}/preds_arma.csv')\n","predictions_s_arma = pd.read_csv(f'{path}/preds_s_arma.csv')\n","predictions_sarima = pd.read_csv(f'{path}/preds_sarima.csv')\n","predictions_prophet = pd.read_csv(f'{path}/preds_prophet.csv')\n","predictions_rnn = pd.read_csv(f'{path}/preds_rnn.csv')\n","predictions_rnn_c_ceemdan = pd.read_csv(f'{path}/preds_rnn_c.csv')\n","predictions_lstm = pd.read_csv(f'{path}/preds_lstm.csv')\n","predictions_lstm_ceemdan = pd.read_csv(f'{path}/preds_lstm_ceemdan.csv')\n","predictions_neuralprophet = pd.read_csv(f'{path}/preds_neuralprophet.csv')\n","predictions_transformer = pd.read_csv(f'{path}/preds_transformer.csv')\n","predictions_transformer_c  = pd.read_csv(f'{path}/preds_transformer_c.csv')"],"metadata":{"id":"RtztcHuX7eus"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_neuralprophet = pd.DataFrame(scaler.inverse_transform(np.array(predictions_neuralprophet['yhat1']).reshape(-1, 1)))\n","predictions_transformer = pd.DataFrame(scaler.inverse_transform(np.array(predictions_transformer.iloc[:-1, 0]).reshape(-1, 1)))"],"metadata":{"id":"Ky6p3oWCNCG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = pd.concat([test[['energy_consumption']].reset_index(), predictions_arma, predictions_s_arma, predictions_sarima, predictions_prophet,\n","           predictions_rnn, predictions_rnn_c_ceemdan, predictions_lstm, predictions_lstm_ceemdan,\n","           predictions_neuralprophet, predictions_transformer, predictions_transformer_c], axis=1)"],"metadata":{"id":"odo6jMmq3Msg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = preds.set_index('date')"],"metadata":{"id":"rRTOMLpWTCz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds.columns = ['test', 'ARMA', 'Seasonal ARMA', 'SARIMA', 'Prophet', 'RNN',\n","                 'RNN with CEEMDAN', 'LSTM', 'LSTM with CEEMDAN', 'Neural Prophet',\n","                 'Transformer', 'Transformer with CEEMDAN']"],"metadata":{"id":"0c2YbrrO3dTT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = ['ARMA', 'Seasonal ARMA', 'SARIMA', 'Prophet', 'RNN',\n","          'RNN with CEEMDAN', 'LSTM', 'LSTM with CEEMDAN', 'Neural Prophet',\n","          'Transformer', 'Transformer with CEEMDAN']\n","\n","results = []\n","for model in models:\n","  rmse = sqrt(mean_squared_error(preds['test'], preds[model]))\n","  mape = mean_absolute_percentage_error(preds['test'], preds[model])\n","  mae = np.abs(preds['test'] - preds[model]).mean()\n","\n","  results.append({'Model': model, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape})\n","\n","results_df = pd.DataFrame(results)\n","display(results_df)"],"metadata":{"id":"AcE43wGdPII4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Djr_yuWhRFw1"},"execution_count":null,"outputs":[]}]}